{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EmotionDetection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOdL52Q3wHM0V9UaUnQAwSN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hansikav/Decision-tree-and-random-forest/blob/main/EmotionDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yicJiALc12oS",
        "outputId": "caa34589-3c0e-4e34-e7ea-0c914a99c48e"
      },
      "source": [
        "!pip install sentencepiece\n"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.91)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWQ-jSi0_ZVn",
        "outputId": "225c1dc7-39e9-4349-d6ea-b4832a17b4d0"
      },
      "source": [
        "pip install transformers[sentencepiece]"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.7/dist-packages (4.5.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.10.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (20.9)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.0.45)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.10.1)\n",
            "Requirement already satisfied: sentencepiece==0.1.91; extra == \"sentencepiece\" in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.1.91)\n",
            "Requirement already satisfied: protobuf; extra == \"sentencepiece\" in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.12.4)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers[sentencepiece]) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[sentencepiece]) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[sentencepiece]) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[sentencepiece]) (1.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers[sentencepiece]) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers[sentencepiece]) (3.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf; extra == \"sentencepiece\"->transformers[sentencepiece]) (56.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFAfRjTK8VxM",
        "outputId": "fa83cbc6-e3de-421b-a393-f1e710e0900c"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDDTG4xL4A2s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbad5588-cc2b-4eb5-b701-bd92064792b7"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/t5-base-finetuned-emotion\")\n",
        "\n",
        "model = AutoModelWithLMHead.from_pretrained(\"mrm8488/t5-base-finetuned-emotion\")\n",
        "\n",
        "\n",
        " "
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/auto/modeling_auto.py:762: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGE3J9Xy6f-f"
      },
      "source": [
        "base_model = model.base_model\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KY5Ui0U5BcH5"
      },
      "source": [
        "class EmoModel(nn.Module):\n",
        "    def __init__(self, base_model, n_classes, base_model_output_size=768, dropout=0.05):\n",
        "        super().__init__()\n",
        "        self.base_model = base_model\n",
        "        \n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(base_model_output_size, base_model_output_size),\n",
        "            Mish(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(base_model_output_size, n_classes)\n",
        "        )\n",
        "        \n",
        "        for layer in self.classifier:\n",
        "            if isinstance(layer, nn.Linear):\n",
        "                layer.weight.data.normal_(mean=0.0, std=0.02)\n",
        "                if layer.bias is not None:\n",
        "                    layer.bias.data.zero_()\n",
        "\n",
        "    def forward(self, input_, *args):\n",
        "        X, attention_mask = input_\n",
        "        hidden_states = self.base_model(X, attention_mask=attention_mask)\n",
        "        \n",
        "       \n",
        "        return self.classifier(hidden_states[0][:, 0, :])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T17iYUEgBkz1"
      },
      "source": [
        "!mkdir -p tokenizer"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHwgLyw-Blo2",
        "outputId": "5c2cef1a-e89d-43a2-94b5-8b2e2241b1ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokenizer.save_pretrained(\"tokenizer\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('tokenizer/tokenizer_config.json',\n",
              " 'tokenizer/special_tokens_map.json',\n",
              " 'tokenizer/spiece.model',\n",
              " 'tokenizer/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1n3zu2JkBoTZ"
      },
      "source": [
        "class TokenizersCollateFn:\n",
        "    def __init__(self, max_tokens=512):\n",
        "\n",
        "        ## RoBERTa uses BPE tokenizer similar to GPT\n",
        "        t = ByteLevelBPETokenizer(\n",
        "            \"tokenizer/vocab.json\",\n",
        "            \"tokenizer/merges.txt\"\n",
        "        )\n",
        "        t._tokenizer.post_processor = BertProcessing(\n",
        "            (\"</s>\", t.token_to_id(\"</s>\")),\n",
        "            (\"<s>\", t.token_to_id(\"<s>\")),\n",
        "        )\n",
        "        t.enable_truncation(max_tokens)\n",
        "        t.enable_padding(pad_id=t.token_to_id(\"<pad>\"))\n",
        "        self.tokenizer = t\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        encoded = self.tokenizer.encode_batch([x[0] for x in batch])\n",
        "        sequences_padded = torch.tensor([enc.ids for enc in encoded])\n",
        "        attention_masks_padded = torch.tensor([enc.attention_mask for enc in encoded])\n",
        "        labels = torch.tensor([x[1] for x in batch])\n",
        "        \n",
        "        return (sequences_padded, attention_masks_padded), labels"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf0Z9pPsB2RG"
      },
      "source": [
        "label2int = {\n",
        "  \"sadness\": 0,\n",
        "  \"joy\": 1,\n",
        "  \"love\": 2,\n",
        "  \"anger\": 3,\n",
        "  \"fear\": 4,\n",
        "  \"surprise\": 5\n",
        "}"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nid1U9qyB3KH",
        "outputId": "a8ef691e-f83e-4217-a6e0-f15f41ad8173",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget https://www.dropbox.com/s/607ptdakxuh5i4s/merged_training.pkl"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-05 15:06:00--  https://www.dropbox.com/s/607ptdakxuh5i4s/merged_training.pkl\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.7.18, 2620:100:6019:18::a27d:412\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.7.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/607ptdakxuh5i4s/merged_training.pkl [following]\n",
            "--2021-05-05 15:06:01--  https://www.dropbox.com/s/raw/607ptdakxuh5i4s/merged_training.pkl\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc50a6fc5f4599ff55dce9823c28.dl.dropboxusercontent.com/cd/0/inline/BN7Y4YxCcRy6FyoBo9JknBlhP-63erQz9LkkbZ2zheo_gTIbzcfBZ-4KjKYYY2_iU2nNW3Ruxh6o6znvaIQ6dNimUX3mlMyUsimnbnAwWoN7UVYZ5rUpgCHdRzp-qC5V7TcNzr9jydLSvL4G8_hmEpGi/file# [following]\n",
            "--2021-05-05 15:06:01--  https://uc50a6fc5f4599ff55dce9823c28.dl.dropboxusercontent.com/cd/0/inline/BN7Y4YxCcRy6FyoBo9JknBlhP-63erQz9LkkbZ2zheo_gTIbzcfBZ-4KjKYYY2_iU2nNW3Ruxh6o6znvaIQ6dNimUX3mlMyUsimnbnAwWoN7UVYZ5rUpgCHdRzp-qC5V7TcNzr9jydLSvL4G8_hmEpGi/file\n",
            "Resolving uc50a6fc5f4599ff55dce9823c28.dl.dropboxusercontent.com (uc50a6fc5f4599ff55dce9823c28.dl.dropboxusercontent.com)... 162.125.6.15, 2620:100:601c:15::a27d:60f\n",
            "Connecting to uc50a6fc5f4599ff55dce9823c28.dl.dropboxusercontent.com (uc50a6fc5f4599ff55dce9823c28.dl.dropboxusercontent.com)|162.125.6.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BN7iWtmA-gB0jlk36WJB3vbrKuJxwDiGC7c1x0UAVSCPSJJfNH0PF144xfcUvo-pYUNBuhs7vD14A-llv7qa4jjqk1ZjonkFFsEIcKdl42Gji4iRkYvdZfJIKIOW-dblXZb_PDT8nWDTMittwDyiyPkxqVPmTYR6B2CE5I3cQdptQLZhvOHnOKa2EGewvrQOK1oCulemJDOalsFi_EZs_AkJup2sX_Cy1f1t-qSmYyarpqaPFvRYonebMug7JNa6H1_a_sl-i0aEq1G-rGOKHTAfKWpAiWCqwp4XGEKryYgiNBhq3Ioi2qkf6FowStpoUst3BJHM4wRMlXqVQH0ZbObdbc-dGPywNhpD-S2jDP8Sgg3b0ryS1iwFWdS82iOPsQk/file [following]\n",
            "--2021-05-05 15:06:01--  https://uc50a6fc5f4599ff55dce9823c28.dl.dropboxusercontent.com/cd/0/inline2/BN7iWtmA-gB0jlk36WJB3vbrKuJxwDiGC7c1x0UAVSCPSJJfNH0PF144xfcUvo-pYUNBuhs7vD14A-llv7qa4jjqk1ZjonkFFsEIcKdl42Gji4iRkYvdZfJIKIOW-dblXZb_PDT8nWDTMittwDyiyPkxqVPmTYR6B2CE5I3cQdptQLZhvOHnOKa2EGewvrQOK1oCulemJDOalsFi_EZs_AkJup2sX_Cy1f1t-qSmYyarpqaPFvRYonebMug7JNa6H1_a_sl-i0aEq1G-rGOKHTAfKWpAiWCqwp4XGEKryYgiNBhq3Ioi2qkf6FowStpoUst3BJHM4wRMlXqVQH0ZbObdbc-dGPywNhpD-S2jDP8Sgg3b0ryS1iwFWdS82iOPsQk/file\n",
            "Reusing existing connection to uc50a6fc5f4599ff55dce9823c28.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49991846 (48M) [application/octet-stream]\n",
            "Saving to: ‘merged_training.pkl’\n",
            "\n",
            "merged_training.pkl 100%[===================>]  47.68M   183MB/s    in 0.3s    \n",
            "\n",
            "2021-05-05 15:06:02 (183 MB/s) - ‘merged_training.pkl’ saved [49991846/49991846]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpY7s1oUB6FT"
      },
      "source": [
        "import pickle\n",
        "\n",
        "## helper function\n",
        "def load_from_pickle(directory):\n",
        "    return pickle.load(open(directory,\"rb\"))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0RGtQjiB98S",
        "outputId": "2e8ac8b6-a3db-404f-e0af-8256859d1847",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "data = load_from_pickle(directory=\"merged_training.pkl\")\n",
        "\n",
        "## using a sample\n",
        "emotions = [ \"sadness\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"]\n",
        "data= data[data[\"emotions\"].isin(emotions)]\n",
        "\n",
        "\n",
        "data = data.sample(n=20000);\n",
        "\n",
        "data.emotions.value_counts().plot.bar()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f96bc58cd90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHnnhH27CDl1"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EppitStwCLU8"
      },
      "source": [
        "data.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bli1aobiCTPE"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Creating training and validation sets using an 80-20 split\n",
        "input_train, input_val, target_train, target_val = train_test_split(data.text.to_numpy(), \n",
        "                                                                    data.emotions.to_numpy(), \n",
        "                                                                    test_size=0.2)\n",
        "\n",
        "# Split the validataion further to obtain a holdout dataset (for testing) -- split 50:50\n",
        "input_val, input_test, target_val, target_test = train_test_split(input_val, target_val, test_size=0.5)\n",
        "\n",
        "\n",
        "## create a dataframe for each dataset\n",
        "train_dataset = pd.DataFrame(data={\"text\": input_train, \"class\": target_train})\n",
        "val_dataset = pd.DataFrame(data={\"text\": input_val, \"class\": target_val})\n",
        "test_dataset = pd.DataFrame(data={\"text\": input_test, \"class\": target_test})\n",
        "final_dataset = {\"train\": train_dataset, \"val\": val_dataset , \"test\": test_dataset }\n",
        "\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6uFqOZNJJNI"
      },
      "source": [
        "def get_emotion(text):\n",
        "  input_ids = tokenizer.encode(text + '</s>', return_tensors='pt')\n",
        "\n",
        "  output = model.generate(input_ids=input_ids,\n",
        "               max_length=2)\n",
        "\n",
        "  dec = [tokenizer.decode(ids) for ids in output]\n",
        "  label = dec[0]\n",
        "  return label\n"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFWStKtaaJ_s",
        "outputId": "e39a4c5c-7e9e-4e06-847f-3589955c7863"
      },
      "source": [
        "! pip install jsonlines"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.7/dist-packages (2.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9GlIiXLRlr_"
      },
      "source": [
        "import jsonlines\n",
        "import re\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "use_stemmer = False\n",
        "if use_stemmer:\n",
        "        porter_stemmer = PorterStemmer()\n",
        "\n",
        "def preprocess_word(word):\n",
        "    # Remove punctuation\n",
        "    word = word.strip('\\'\"?!,.():;')\n",
        "    # Convert more than 2 letter repetitions to 2 letter\n",
        "    # funnnnny --> funny\n",
        "    word = re.sub(r'(.)\\1+', r'\\1\\1', word)\n",
        "    # Remove - & '\n",
        "    word = re.sub(r'(-|\\')', '', word)\n",
        "    return word\n",
        "\n",
        "def handle_emojis(tweet):\n",
        "    # Smile -- :), : ), :-), (:, ( :, (-:, :')\n",
        "    tweet = re.sub(r'(:\\s?\\)|:-\\)|\\(\\s?:|\\(-:|:\\'\\))', ' smile ', tweet)\n",
        "    # Laugh -- :D, : D, :-D, xD, x-D, XD, X-D\n",
        "    tweet = re.sub(r'(:\\s?D|:-D|x-?D|X-?D)', ' laugh ', tweet)\n",
        "    # Love -- <3, :*\n",
        "    tweet = re.sub(r'(<3|:\\*)', ' love ', tweet)\n",
        "    # Wink -- ;-), ;), ;-D, ;D, (;,  (-;\n",
        "    tweet = re.sub(r'(;-?\\)|;-?D|\\(-?;)', ' wink ', tweet)\n",
        "    # Sad -- :-(, : (, :(, ):, )-:\n",
        "    tweet = re.sub(r'(:\\s?\\(|:-\\(|\\)\\s?:|\\)-:)', ' sad ', tweet)\n",
        "    # Cry -- :,(, :'(, :\"(\n",
        "    tweet = re.sub(r'(:,\\(|:\\'\\(|:\"\\()', ' cry ', tweet)\n",
        "    return tweet\n",
        "\n",
        "\n",
        "def preprocess(tweet):\n",
        "  processed_tweet = []\n",
        "  tweet = tweet.lower()\n",
        "  tweet = re.sub(r'((www\\.[\\S]+)|(https?://[\\S]+))', '', tweet)\n",
        "  tweet = re.sub(r'@[\\S]+', '', tweet)\n",
        "  tweet = tweet.split('url')[0]\n",
        "  tweet = tweet.replace('url','')\n",
        "  tweet = tweet.replace('qt','')\n",
        "  tweet = re.sub(r'\\brt\\b', '', tweet)\n",
        "  tweet = re.sub(r'\\.{2,}', ' ', tweet)\n",
        "  tweet = tweet.strip(' \"\\'')\n",
        "  tweet = handle_emojis(tweet)\n",
        "  tweet = re.sub(r'\\s+', ' ', tweet)\n",
        "  words = tweet.split()\n",
        "\n",
        "  for word in words:\n",
        "      word = preprocess_word(word)\n",
        "      if True:\n",
        "          if use_stemmer:\n",
        "              word = str(porter_stemmer.stem(word))\n",
        "          processed_tweet.append(word)\n",
        "\n",
        "  return ' '.join(processed_tweet)\n",
        "\n",
        "preprocessed_tweets = {}\n",
        "sentiment_labels = {}\n",
        "with jsonlines.open('output.jsonl', mode='w') as writer:\n",
        "  with jsonlines.open('train_tweets.jsonl') as f:\n",
        "    for line in f.iter():\n",
        "        # Preprocess text\n",
        "        text = preprocess(line['text'])\n",
        "        emotion = get_emotion(text)\n",
        "        line['text']= text\n",
        "        line['emotion'] = emotion.replace('<pad> ','')\n",
        "        writer.write(line)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsAFqx4kOUrA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "889ba0a2-48ea-4ed3-84d8-d8e52bbbba1f"
      },
      "source": [
        "print(preprocess(\" I'm more concerned with the side effects of the vaccine than I am with the symptoms of covid.\\nI'm a healthy man.\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "im more concerned with the side effects of the vaccine than i am with the symptoms of covid im a healthy man\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXK-7wS_I2rn"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import re\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "# Packages for data preparation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.corpus import stopwords\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Packages for modeling\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import regularizers"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUC8gVzBJSWE"
      },
      "source": [
        "NB_WORDS = 10000  # Parameter indicating the number of words we'll put in the dictionary\n",
        "NB_START_EPOCHS = 20  # Number of epochs we usually start to train with\n",
        "BATCH_SIZE = 512  # Size of the batches used in the mini-batch gradient descent\n",
        "MAX_LEN = 20  # Maximum number of words in a sequence"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCT05SJFJWZm",
        "outputId": "826c8565-1980-45bd-b5bc-731216d5e439"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFDkbaW2Jc3n"
      },
      "source": [
        "def deep_model(model, X_train, y_train, X_valid, y_valid):\n",
        "    '''\n",
        "    Function to train a multi-class model. The number of epochs and \n",
        "    batch_size are set by the constants at the top of the\n",
        "    notebook. \n",
        "    \n",
        "    Parameters:\n",
        "        model : model with the chosen architecture\n",
        "        X_train : training features\n",
        "        y_train : training target\n",
        "        X_valid : validation features\n",
        "        Y_valid : validation target\n",
        "    Output:\n",
        "        model training history\n",
        "    '''\n",
        "    model.compile(optimizer='rmsprop'\n",
        "                  , loss='categorical_crossentropy'\n",
        "                  , metrics=['accuracy'])\n",
        "    \n",
        "    history = model.fit(X_train\n",
        "                       , y_train\n",
        "                       , epochs=NB_START_EPOCHS\n",
        "                       , batch_size=BATCH_SIZE\n",
        "                       , validation_data=(X_valid, y_valid)\n",
        "                       , verbose=0)\n",
        "    return history"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jfyg5NiJJeBR"
      },
      "source": [
        "def eval_metric(model, history, metric_name):\n",
        "    '''\n",
        "    Function to evaluate a trained model on a chosen metric. \n",
        "    Training and validation metric are plotted in a\n",
        "    line chart for each epoch.\n",
        "    \n",
        "    Parameters:\n",
        "        history : model training history\n",
        "        metric_name : loss or accuracy\n",
        "    Output:\n",
        "        line chart with epochs of x-axis and metric on\n",
        "        y-axis\n",
        "    '''\n",
        "    metric = history.history[metric_name]\n",
        "    val_metric = history.history['val_' + metric_name]\n",
        "\n",
        "    e = range(1, NB_START_EPOCHS + 1)\n",
        "\n",
        "    plt.plot(e, metric, 'bo', label='Train ' + metric_name)\n",
        "    plt.plot(e, val_metric, 'b', label='Validation ' + metric_name)\n",
        "    plt.xlabel('Epoch number')\n",
        "    plt.ylabel(metric_name)\n",
        "    plt.title('Comparing training and validation ' + metric_name + ' for ' + model.name)\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poxswc0HJjDT"
      },
      "source": [
        "def test_model(model, X_train, y_train, X_test, y_test, epoch_stop):\n",
        "    '''\n",
        "    Function to test the model on new data after training it\n",
        "    on the full training data with the optimal number of epochs.\n",
        "    \n",
        "    Parameters:\n",
        "        model : trained model\n",
        "        X_train : training features\n",
        "        y_train : training target\n",
        "        X_test : test features\n",
        "        y_test : test target\n",
        "        epochs : optimal number of epochs\n",
        "    Output:\n",
        "        test accuracy and test loss\n",
        "    '''\n",
        "    model.fit(X_train\n",
        "              , y_train\n",
        "              , epochs=epoch_stop\n",
        "              , batch_size=BATCH_SIZE\n",
        "              , verbose=0)\n",
        "    results = model.evaluate(X_test, y_test)\n",
        "    print()\n",
        "    print('Test accuracy: {0:.2f}%'.format(results[1]*100))\n",
        "    return results"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KTbb8WiJpGl"
      },
      "source": [
        "def remove_stopwords(input_text):\n",
        "    '''\n",
        "    Function to remove English stopwords from a Pandas Series.\n",
        "    \n",
        "    Parameters:\n",
        "        input_text : text to clean\n",
        "    Output:\n",
        "        cleaned Pandas Series \n",
        "    '''\n",
        "    stopwords_list = stopwords.words('english')\n",
        "    # Some words which might indicate a certain sentiment are kept via a whitelist\n",
        "    whitelist = [\"n't\", \"not\", \"no\"]\n",
        "    words = input_text.split() \n",
        "    clean_words = [word for word in words if (word not in stopwords_list or word in whitelist) and len(word) > 1] \n",
        "    return \" \".join(clean_words)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpDR8N0yJvO8"
      },
      "source": [
        "def remove_mentions(input_text):\n",
        "    '''\n",
        "    Function to remove mentions, preceded by @, in a Pandas Series\n",
        "    \n",
        "    Parameters:\n",
        "        input_text : text to clean\n",
        "    Output:\n",
        "        cleaned Pandas Series \n",
        "    '''\n",
        "    return re.sub(r'@\\w+', '', input_text)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2osZw83dJ47p"
      },
      "source": [
        "def compare_models_by_metric(model_1, model_2, model_hist_1, model_hist_2, metric):\n",
        "    '''\n",
        "    Function to compare a metric between two models \n",
        "    \n",
        "    Parameters:\n",
        "        model_hist_1 : training history of model 1\n",
        "        model_hist_2 : training history of model 2\n",
        "        metrix : metric to compare, loss, acc, val_loss or val_acc\n",
        "        \n",
        "    Output:\n",
        "        plot of metrics of both models\n",
        "    '''\n",
        "    metric_model_1 = model_hist_1.history[metric]\n",
        "    metric_model_2 = model_hist_2.history[metric]\n",
        "\n",
        "    e = range(1, NB_START_EPOCHS + 1)\n",
        "    \n",
        "    metrics_dict = {\n",
        "        'acc' : 'Training Accuracy',\n",
        "        'loss' : 'Training Loss',\n",
        "        'val_acc' : 'Validation accuracy',\n",
        "        'val_loss' : 'Validation loss'\n",
        "    }\n",
        "    \n",
        "    metric_label = metrics_dict[metric]\n",
        "\n",
        "    plt.plot(e, metric_model_1, 'bo', label=model_1.name)\n",
        "    plt.plot(e, metric_model_2, 'b', label=model_2.name)\n",
        "    plt.xlabel('Epoch number')\n",
        "    plt.ylabel(metric_label)\n",
        "    plt.title('Comparing ' + metric_label + ' between models')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UivPfqtuJ8La"
      },
      "source": [
        "def optimal_epoch(model_hist):\n",
        "    '''\n",
        "    Function to return the epoch number where the validation loss is\n",
        "    at its minimum\n",
        "    \n",
        "    Parameters:\n",
        "        model_hist : training history of model\n",
        "\n",
        "    Output:\n",
        "        epoch number with minimum validation loss\n",
        "    '''\n",
        "    min_epoch = np.argmin(model_hist.history['val_loss']) + 1\n",
        "    print(\"Minimum validation loss reached in epoch {}\".format(min_epoch))\n",
        "    return min_epoch"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3ht0cieKI_x"
      },
      "source": [
        "import numpy\n",
        "df = pd.read_csv('data1.csv', names=[\"id\",\"text\",\"misinfo\", \"stance\"])\n",
        "\n",
        "#df1 =  pd.read_json('output.jsonl',lines='true')\n",
        "emotion=[]\n",
        "id = []\n",
        "text = []\n",
        "with jsonlines.open('output.jsonl') as f:\n",
        "    for line in f.iter():\n",
        "        # Preprocess text\n",
        "        text.append(line['text'])\n",
        "        id.append(numpy.int64(line['id']))\n",
        "        emotion.append(line['emotion'])\n",
        "\n",
        "df1 = pd.DataFrame({'id':id,'tweet':text,'emotion':emotion})\n"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyWA_g8PEyiC",
        "outputId": "a7e56a7c-01b1-47ab-9b01-d44ba0ec45f0"
      },
      "source": [
        "df1[\"id\"][384]"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1339943721127669761"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "L_q9E5baBYPx",
        "outputId": "630b5976-f6fc-4649-efa8-622e11e4dc72"
      },
      "source": [
        "df1[df1['id']==1340015106206392321]"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>1340015106206392321</td>\n",
              "      <td>so a bit like the virus then yet somehow we al...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     id  ... emotion\n",
              "91  1340015106206392321  ...     joy\n",
              "\n",
              "[1 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDk8E85f5KNA",
        "outputId": "ed54e0c8-6abe-40f8-a12f-2e96395ea17e"
      },
      "source": [
        "df['stance'].value_counts()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "not_relevant    737\n",
              "agree           646\n",
              "disagree        371\n",
              "no_stance       246\n",
              "Name: stance, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqFw8syU5TIt",
        "outputId": "ec026c13-1737-4bac-88f9-daf35acf5444"
      },
      "source": [
        "df1['emotion'].value_counts()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fear        808\n",
              "anger       415\n",
              "joy         347\n",
              "sadness      60\n",
              "surprise      9\n",
              "love          1\n",
              "Name: emotion, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khe3wiR3FaNG"
      },
      "source": [
        "df3 = pd.merge(df,df1,on = 'id', how = 'left')\n"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "id": "zd77HwvMCDQB",
        "outputId": "9e620ef7-6d0c-4b9c-e424-db82fcf6d89c"
      },
      "source": [
        "df3"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>misinfo</th>\n",
              "      <th>stance</th>\n",
              "      <th>tweet</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1340015106206392321</td>\n",
              "      <td>@meetnpatatas @RealMattCouch @Progressivemagi ...</td>\n",
              "      <td>More people will die as a result of a negative...</td>\n",
              "      <td>agree</td>\n",
              "      <td>so a bit like the virus then yet somehow we al...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1340570906662322176</td>\n",
              "      <td>@armyveteran13 I said when the virus was first...</td>\n",
              "      <td>The COVID-19 vaccine causes infertility or mis...</td>\n",
              "      <td>agree</td>\n",
              "      <td>i said when the virus was first declared that ...</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1344724371865182208</td>\n",
              "      <td>Bombshell Interview With Del Bigtree: COVID Va...</td>\n",
              "      <td>The COVID-19 vaccine causes infertility or mis...</td>\n",
              "      <td>agree</td>\n",
              "      <td>bombshell interview with del bigtree covid vac...</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1345709249469546496</td>\n",
              "      <td>YOLO- berichtgeving:   \"COVID Vaccine Caused 4...</td>\n",
              "      <td>The COVID-19 vaccine causes Bell's palsy.</td>\n",
              "      <td>agree</td>\n",
              "      <td>yolo berichtgeving covid vaccine caused 4 peop...</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1344586458791723008</td>\n",
              "      <td>@FatEmperor Natural immunity, I build up my bo...</td>\n",
              "      <td>Natural COVID-19 immunity is better than immun...</td>\n",
              "      <td>agree</td>\n",
              "      <td>natural immunity i build up my body for 19 yea...</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>1340059526641410048</td>\n",
              "      <td>If the coronavirus vaccine doesn't cause autis...</td>\n",
              "      <td>The COVID-19 vaccine causes infertility or mis...</td>\n",
              "      <td>not_relevant</td>\n",
              "      <td>if the coronavirus vaccine doesnt cause autism...</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>1340059526641410048</td>\n",
              "      <td>If the coronavirus vaccine doesn't cause autis...</td>\n",
              "      <td>The COVID-19 vaccine causes Bell's palsy.</td>\n",
              "      <td>not_relevant</td>\n",
              "      <td>if the coronavirus vaccine doesnt cause autism...</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>1340342873867186177</td>\n",
              "      <td>I'm more concerned with the side effects of th...</td>\n",
              "      <td>There are severe side effects of the COVID-19 ...</td>\n",
              "      <td>agree</td>\n",
              "      <td>im more concerned with the side effects of the...</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>1340342873867186177</td>\n",
              "      <td>I'm more concerned with the side effects of th...</td>\n",
              "      <td>More people will die as a result of a negative...</td>\n",
              "      <td>agree</td>\n",
              "      <td>im more concerned with the side effects of the...</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>1343573920440582147</td>\n",
              "      <td>Covid vaccine giving ppl of color Bell's palsy...</td>\n",
              "      <td>The COVID-19 vaccine causes Bell's palsy.</td>\n",
              "      <td>agree</td>\n",
              "      <td>covid vaccine giving ppl of color bells palsy ...</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       id  ... emotion\n",
              "0     1340015106206392321  ...     joy\n",
              "1     1340570906662322176  ...   anger\n",
              "2     1344724371865182208  ...   anger\n",
              "3     1345709249469546496  ...   anger\n",
              "4     1344586458791723008  ...   anger\n",
              "...                   ...  ...     ...\n",
              "1995  1340059526641410048  ...    fear\n",
              "1996  1340059526641410048  ...    fear\n",
              "1997  1340342873867186177  ...    fear\n",
              "1998  1340342873867186177  ...    fear\n",
              "1999  1343573920440582147  ...    fear\n",
              "\n",
              "[2000 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZvhJ6HpCNob",
        "outputId": "b36d7b52-488c-4ddf-9808-5e1a2db48f94"
      },
      "source": [
        "\n",
        "df3['tweet'].value_counts()"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "i am not going to take the covid19 vaccine                                                                                                                                                                                                      8\n",
              "the covid19 vaccine could kill you with a allergic reaction 👀                                                                                                                                                                                   7\n",
              "the covid19 vaccine is fake                                                                                                                                                                                                                     7\n",
              "                                                                                                                                                                                                                                                6\n",
              "will the covid19 vaccine cause infertility in women                                                                                                                                                                                             6\n",
              "                                                                                                                                                                                                                                               ..\n",
              "this waste of human flesh is evil bill gates admits covid vaccine alters dna                                                                                                                                                                    1\n",
              "eugenics population control social engineering technocracy these are not conspiracy theories anymore folks the cabal wants to cull off a percentage of the global population and have the ones who remain surveilled tracked and enslaved 👇👇    1\n",
              "does the covid vaccine change your dna no heres what it does do and how it helps to keep you immune to the virus                                                                                                                                1\n",
              "the covid vax hadnt even been tested in animals  how on earth can a smart person be beyond dumb taking an experimental rna vaccine that potentially alters the dna  fir a virus with an overall 99.7% recovery rate ludicrous                   1\n",
              "the amount of ppl more scared of the covid vaccine than the virus itself is as astounding as it is scary                                                                                                                                        1\n",
              "Name: tweet, Length: 1617, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJxlzQYNKO17",
        "outputId": "9232ea7c-aff6-442d-c144-0d1c75b53570"
      },
      "source": [
        "df3[\"comb\"] = df3[\"tweet\"] + \" \" + df3[\"emotion\"] + \" \" + df3[\"misinfo\"] \n",
        "df3 = df3.reindex(np.random.permutation(df3.index))  \n",
        "df3 = df3[['comb', 'stance']]\n",
        "df3.text = df3.comb.apply(remove_stopwords).apply(remove_mentions)\n",
        "df3.head(10)\n",
        "df3.to_csv('df3.csv')"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFbbrKNOMb3C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d96399d5-05d5-4f86-e139-07da2c10549d"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df3.comb, df3.stance, test_size=0.1, random_state=37)\n",
        "print('# Train data samples:', X_train.shape[0])\n",
        "print('# Test data samples:', X_test.shape[0])\n",
        "assert X_train.shape[0] == y_train.shape[0]\n",
        "assert X_test.shape[0] == y_test.shape[0]"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Train data samples: 1800\n",
            "# Test data samples: 200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFG7mjDNCqGH",
        "outputId": "d1b4c9ee-1458-4258-c0b5-2d33d1a0f80e"
      },
      "source": [
        "tk = Tokenizer(num_words=NB_WORDS,\n",
        "               filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
        "               lower=True,\n",
        "               char_level=False,\n",
        "               split=' ')\n",
        "tk.fit_on_texts(X_train)\n",
        "\n",
        "print('Fitted tokenizer on {} documents'.format(tk.document_count))\n",
        "print('{} words in dictionary'.format(tk.num_words))\n",
        "print('Top 5 most common words are:', collections.Counter(tk.word_counts).most_common(5))"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitted tokenizer on 1800 documents\n",
            "10000 words in dictionary\n",
            "Top 5 most common words are: [('the', 4509), ('vaccine', 3335), ('covid', 3091), ('19', 2183), ('a', 1654)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3nEmrunL8ts"
      },
      "source": [
        "X_train_oh = tk.texts_to_matrix(X_train, mode='binary')\n",
        "X_test_oh = tk.texts_to_matrix(X_test, mode='binary')"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAiAC6GgMA2J"
      },
      "source": [
        "label_to_index = {\n",
        "    'not_relevant': 0, \n",
        "    'no_stance': 1, \n",
        "    'disagree': 2,\n",
        "    'agree': 3\n",
        "}\n",
        "\n",
        "y_train_oh = y_train.apply(\n",
        "    lambda x: label_to_index[x])\n",
        "    \n",
        "y_train_oh = np.asarray(y_train_oh) \\\n",
        "            .astype('float32')\n",
        "\n",
        "y_test_oh = y_test.apply(\n",
        "    lambda x: label_to_index[x])\n",
        "\n",
        "y_test_oh = np.asarray(y_test_oh) \\\n",
        "            .astype('float32')"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHTBQlcxMEMc",
        "outputId": "b9cce6c1-d9f7-465b-cba5-9759e620c0ed"
      },
      "source": [
        "y_train_oh[:5]"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3., 3., 2., 3., 2.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Hgvrdm7MIbe",
        "outputId": "eb3aacc2-0974-4a23-8ee9-26df45ce4192"
      },
      "source": [
        "\n",
        "y_train"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1890           agree\n",
              "244            agree\n",
              "1189        disagree\n",
              "937            agree\n",
              "348         disagree\n",
              "            ...     \n",
              "189         disagree\n",
              "1742           agree\n",
              "1561        disagree\n",
              "1343    not_relevant\n",
              "1122           agree\n",
              "Name: stance, Length: 1800, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYArywgtMQ3s",
        "outputId": "2ec0db22-ebd1-4d35-ecbf-62bcc310c5b9"
      },
      "source": [
        "le = LabelEncoder()\n",
        "y_train_le = le.fit_transform(y_train)\n",
        "y_test_le = le.transform(y_test)\n",
        "y_train_oh = to_categorical(y_train_le)\n",
        "y_test_oh = to_categorical(y_test_le)\n",
        "print('\"{}\" is converted into {}'.format(y_train_le[0], y_train_oh[0]))"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"0\" is converted into [1. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ar2ydDWqMWB1",
        "outputId": "fcf21e04-881d-40aa-87d0-4bf06af76a2e"
      },
      "source": [
        "y_train_le"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, ..., 1, 3, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B55r5NzBMZh7",
        "outputId": "12906790-a63b-4537-87c1-41bbd744499f"
      },
      "source": [
        "y_train_oh[:5]"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0.],\n",
              "       [1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBpJizphMeZw",
        "outputId": "6559d676-8ad2-4eff-daf0-6a70f29cdd8a"
      },
      "source": [
        "X_train_rest, X_valid, y_train_rest, y_valid = train_test_split(X_train_oh, y_train_oh, test_size=0.1, random_state=37)\n",
        "\n",
        "assert X_valid.shape[0] == y_valid.shape[0]\n",
        "assert X_train_rest.shape[0] == y_train_rest.shape[0]\n",
        "\n",
        "print('Shape of validation set:',X_valid.shape)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of validation set: (180, 10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzndY-v4MjEC",
        "outputId": "54412852-18d3-479b-929a-c949adab3df7"
      },
      "source": [
        "drop_model = models.Sequential()\n",
        "drop_model.add(layers.Dense(128, activation='relu', input_shape=(NB_WORDS,)))\n",
        "drop_model.add(layers.Dropout(0.5))\n",
        "drop_model.add(layers.Dense(64, activation='relu'))\n",
        "drop_model.add(layers.Dropout(0.5))\n",
        "drop_model.add(layers.Dense(32, activation='relu'))\n",
        "drop_model.add(layers.Dropout(0.5))\n",
        "drop_model.add(layers.Dense(512, activation='relu'))\n",
        "drop_model.add(layers.Dense(4, activation='softmax'))\n",
        "drop_model.summary()"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 128)               1280128   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 512)               16896     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 4)                 2052      \n",
            "=================================================================\n",
            "Total params: 1,309,412\n",
            "Trainable params: 1,309,412\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEBQtygUMpqx",
        "outputId": "be3793f7-a503-4e04-ce17-da1ac8affe23"
      },
      "source": [
        "\n",
        "drop_history = deep_model(drop_model, X_train_rest, y_train_rest, X_valid, y_valid)\n",
        "drop_min = optimal_epoch(drop_history)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minimum validation loss reached in epoch 13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ybh4FwtEMxLm",
        "outputId": "011b525a-e14e-49ec-ca4e-1d7d4e60dc15"
      },
      "source": [
        "drop_results = test_model(drop_model, X_train_oh, y_train_oh, X_test_oh, y_test_oh, drop_min)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 0s 4ms/step - loss: 5.0009 - accuracy: 0.5200\n",
            "\n",
            "Test accuracy: 52.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgX8WZCYNKYZ"
      },
      "source": [
        "def get_target_text(m_id):\n",
        "  m_id = int(m_id)\n",
        "  if m_id == 1:\n",
        "    return \"RNA alters a person's DNA when taking the COVID-19 vaccine.\"\n",
        "  if m_id == 2:\n",
        "    return \"The COVID-19 vaccine causes infertility or miscarriages in women.\"\n",
        "  if m_id == 3:\n",
        "    return \"Natural COVID-19 immunity is better than immunity derived from a COVID-19 vaccine.\"\n",
        "  if m_id == 4:\n",
        "    return \"The COVID-19 vaccine causes Bell's palsy.\"\n",
        "  if m_id == 7:\n",
        "    return \"The COVID-19 vaccine contains tissue from aborted fetuses.\"\n",
        "  if m_id == 8:\n",
        "    return \"The COVID-19 vaccine was developed to control the general population either through microchip tracking or nanotransducers in our brains.\"\n",
        "  if m_id == 9:\n",
        "    return \"More people will die as a result of a negative side effect to the COVID-19 vaccine than would actually die from the coronavirus.\"\n",
        "  if m_id == 10:\n",
        "    return \"There are severe side effects of the COVID-19 vaccines, worse than having the virus.\""
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YP-Me_eNSAc"
      },
      "source": [
        "def predict_stance(tweet):\n",
        "  stance_vector = drop_model.predict(tweet)[0]\n",
        "  stance = np.argmax(stance_vector)\n",
        "  if stance == 0:\n",
        "    stance_label = 'agree'\n",
        "  elif stance == 1:\n",
        "    stance_label = 'disagree'\n",
        "  elif stance == 2:\n",
        "    stance_label = 'no_stance'\n",
        "  else:\n",
        "    stance_label = 'not_relevant'\n",
        "  \n",
        "  return stance_vector, stance_label"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_gNJ3iyNiF2"
      },
      "source": [
        "def predict_emotion_stance(tweet, m_id):\n",
        "  target = get_target_text(m_id)\n",
        "  emotion = get_emotion(preprocess(tweet))\n",
        "  input = tweet + \" \" + emotion + \" \" + target\n",
        "  input = remove_mentions(input)\n",
        "  input = remove_stopwords(input)\n",
        "  input = tk.texts_to_matrix([input], mode='binary')\n",
        "  stance_vector, stance_label = predict_stance(input)\n",
        "\n",
        "  return target, emotion, stance_label, stance_vector\n",
        "  #print(\"Tweet:\",tweet, \"\\nM_target:\", target, \"\\nSentiment:\", sentiment,\"\\n\",sentiment_scores, \"\\nStance:\", stance_label, \"\\n\",stance_vector)"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBR0YJqdONar",
        "outputId": "763d1542-dc97-4895-bba2-06b98b1283a7"
      },
      "source": [
        "tweet = \"My mom desen't want me to continue my education because we have to get a covid vaccine and she says it's a \\\"fact\\\" that it causes infertility.\"\n",
        "target, emotion,stance_label, stance_vector = predict_emotion_stance(tweet, 2)\n",
        "print(\"Tweet:\",tweet, \"\\nM_target:\", target, \"\\nEmotion:\", emotion.replace('<pad>',''),\n",
        " \"\\nStance:\", stance_label, \"\\n\",stance_vector)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tweet: My mom desen't want me to continue my education because we have to get a covid vaccine and she says it's a \"fact\" that it causes infertility. \n",
            "M_target: The COVID-19 vaccine causes infertility or miscarriages in women. \n",
            "Emotion:  anger \n",
            "Stance: agree \n",
            " [9.9877781e-01 2.2095155e-05 1.9871324e-08 1.2000395e-03]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}